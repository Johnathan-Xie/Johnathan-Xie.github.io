<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Johnathan Xie</title>

    <meta name="author" content="Johnathan Xie">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Johnathan Xie
                </p>
                <p>I'm an undergraduate Computer Science student at Stanford advised by <a href="https://jiajunwu.com/">Jiajun Wu</a> and affiliated with <a href="https://ai.stanford.edu/">Stanford AI Lab (SAIL)</a>. I am broadly interested in self-supervised and weakly supervised machine learning methods that generalize well at scale.</a>
                </p>
                <p>
                  Previously I have done research advised by <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a>. I was also previously a machine learning intern at <a href="https://www.getcruise.com/">Cruise</a></a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:jwxie@stanford.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/johnathan-xie-cv.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/johnathan-xie/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=dsmssvcAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/johnathan_xie">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Johnathan-Xie">Github</a>
                </p>
              </td>
              <td width="15%">
                <img src="images/profile_picture.jpeg"
                width="200" 
                height="240">
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td width="25%">
        <div class="one">
          <div class="two"><img src='images/ats.png' width="160" vspace="20"></div>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2409.19817">
          <span class="papertitle">Calibrating Language Models with Adaptive Temperature Scaling</span>
        </a>
        <br>
        <strong>Johnathan Xie*</strong>, Annie S. Chen*, Yoonho Lee, Eric Mitchell, Chelsea Finn
        <br>
        <em>ICLR</em>, 2024
        <br>
        [<a href="https://github.com/Johnathan-Xie/adaptive-temperature-scaling">code</a>]
        [<a href="https://arxiv.org/pdf/2409.19817">paper</a>]
        <p></p>
        <p>
          ATS performs generalized calibration of RLHFâ€™d LLMs such that model confidence scores accurately reflect the probability of being correct.
        </p>
      </td>
    </tr>
    <tr>
      <td width="25%">
        <div class="one">
          <div class="two"><img src='images/sma.png' width="160" vspace="20"></div>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2402.14789">
          <span class="papertitle">Self-Guided Masked Autoencoders for Domain-Agnostic Self-Supervised Learning</span>
        </a>
        <br>
        <strong>Johnathan Xie*</strong>, Yoonho Lee, Annie S. Chen, Chelsea Finn
        <br>
        <em>ICLR</em>, 2024
        <br>
        [<a href="https://github.com/Johnathan-Xie/sma">code</a>]
        [<a href="https://arxiv.org/pdf/2402.14789">paper</a>]
        <p></p>
        <p>
          Masking inputs based on a model's attention map can create a strong, domain-agnostic masking strategy for masked modeling.
        </p>
      </td>
    </tr>
    <tr>
      <td width="25%">
        <div class="one">
          <div class="two"><img src='images/zsd-yolo.png' width="160" vspace="20"></div>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2109.12066">
          <span class="papertitle">Zero-shot Object Detection Through Vision-Language Embedding Alignment</span>
        </a>
        <br>
        <strong>Johnathan Xie</strong>, Shuai Zheng
        <br>
        <em>ICDM workshop FOMO-VL</em>, 2022
        <br>
        [<a href="https://github.com/Johnathan-Xie/ZSD-YOLO">code</a>]
        [<a href="https://arxiv.org/pdf/2109.12066">paper</a>]
        <p></p>
        <p>
          ZSD-YOLO performs real-time zero-shot object detection by distilling the CLIP embedding space into YOLOv5.
        </p>
      </td>
    </tr>
  </body>
</html>
